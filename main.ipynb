{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  2 09:32:34 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...    Off |   00000000:0A:00.0  On |                  N/A |\n",
      "|  0%   48C    P5             24W /  215W |     791MiB /   8192MiB |     13%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2062      G   /usr/lib/Xorg                                 229MiB |\n",
      "|    0   N/A  N/A      3391      G   /usr/bin/kwalletd5                              2MiB |\n",
      "|    0   N/A  N/A      3458      G   /usr/bin/ksmserver                              2MiB |\n",
      "|    0   N/A  N/A      3460      G   /usr/bin/kded5                                  2MiB |\n",
      "|    0   N/A  N/A      3461      G   /usr/bin/kwin_x11                             113MiB |\n",
      "|    0   N/A  N/A      3514      G   /usr/bin/plasmashell                           37MiB |\n",
      "|    0   N/A  N/A      3537      G   ...b/polkit-kde-authentication-agent-1         20MiB |\n",
      "|    0   N/A  N/A      3539      G   /usr/lib/xdg-desktop-portal-kde                 2MiB |\n",
      "|    0   N/A  N/A      3677      G   /usr/bin/kclockd                                2MiB |\n",
      "|    0   N/A  N/A      3678      G   /usr/lib/kdeconnectd                            2MiB |\n",
      "|    0   N/A  N/A      3681      G   /usr/bin/latte-dock                            18MiB |\n",
      "|    0   N/A  N/A      3698      G   /usr/bin/kaccess                                2MiB |\n",
      "|    0   N/A  N/A      3708      G   /usr/lib/DiscoverNotifier                       2MiB |\n",
      "|    0   N/A  N/A      3710      G   /usr/bin/kalendarac                             2MiB |\n",
      "|    0   N/A  N/A      3727      G   /usr/bin/kmix                                   2MiB |\n",
      "|    0   N/A  N/A      3856      G   /usr/bin/akonadi_control                        2MiB |\n",
      "|    0   N/A  N/A      4018      G   /usr/bin/akonadi_akonotes_resource              2MiB |\n",
      "|    0   N/A  N/A      4019      G   /usr/bin/akonadi_archivemail_agent              2MiB |\n",
      "|    0   N/A  N/A      4020      G   /usr/bin/akonadi_birthdays_resource             2MiB |\n",
      "|    0   N/A  N/A      4021      G   /usr/bin/akonadi_contacts_resource              2MiB |\n",
      "|    0   N/A  N/A      4022      G   .../bin/akonadi_followupreminder_agent          2MiB |\n",
      "|    0   N/A  N/A      4023      G   /usr/bin/akonadi_ical_resource                  2MiB |\n",
      "|    0   N/A  N/A      4031      G   /usr/bin/akonadi_indexing_agent                 2MiB |\n",
      "|    0   N/A  N/A      4033      G   /usr/bin/akonadi_maildir_resource               2MiB |\n",
      "|    0   N/A  N/A      4034      G   /usr/bin/akonadi_maildispatcher_agent           2MiB |\n",
      "|    0   N/A  N/A      4037      G   /usr/bin/akonadi_mailfilter_agent               2MiB |\n",
      "|    0   N/A  N/A      4038      G   /usr/bin/akonadi_mailmerge_agent                2MiB |\n",
      "|    0   N/A  N/A      4041      G   /usr/bin/akonadi_migration_agent                2MiB |\n",
      "|    0   N/A  N/A      4043      G   /usr/bin/akonadi_newmailnotifier_agent          2MiB |\n",
      "|    0   N/A  N/A      4044      G   /usr/bin/akonadi_notes_agent                    2MiB |\n",
      "|    0   N/A  N/A      4045      G   /usr/bin/akonadi_sendlater_agent                2MiB |\n",
      "|    0   N/A  N/A      4046      G   /usr/bin/akonadi_unifiedmailbox_agent           2MiB |\n",
      "|    0   N/A  N/A     56344      G   ...sion,SpareRendererForSitePerProcess        110MiB |\n",
      "|    0   N/A  N/A    205360      G   plasma-systemmonitor                           20MiB |\n",
      "|    0   N/A  N/A    232983      G   /usr/lib/firefox/firefox                      122MiB |\n",
      "|    0   N/A  N/A    236339      G   /usr/bin/dolphin                                2MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy/pyenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Normalize, ToTensor, Compose\n",
    "from torchvision.models import densenet121, densenet169, densenet201\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(type=\"cuda\", index=0)\n",
    "else:\n",
    "    device = torch.device(type=\"cpu\", index=0)\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 9132\n"
     ]
    }
   ],
   "source": [
    "manual_seed = random.randint(1, 10000)\n",
    "print(f\"Random Seed: {manual_seed}\")\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Dataset Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_image(input_path, output_path):\n",
    "#     try:\n",
    "#     \n",
    "#         image = Image.open(input_path)\n",
    "\n",
    "#         \n",
    "#         if image.mode != 'RGBA':\n",
    "#             image = image.convert('RGBA')\n",
    "\n",
    "#         \n",
    "#         image = image.resize((256, 256))\n",
    "\n",
    "#        \n",
    "#         image.save(output_path, 'PNG')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image {input_path}: {e}\")\n",
    "\n",
    "# \n",
    "# root_folder = \"class_dirs_orignal\"\n",
    "# output_folder = \"class_dirs_final\"\n",
    "\n",
    "# \n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# \n",
    "# for class_name in os.listdir(root_folder):\n",
    "#     class_path = os.path.join(root_folder, class_name)\n",
    "#     output_class_path = os.path.join(output_folder, class_name)\n",
    "\n",
    "#     \n",
    "#     if not os.path.isdir(class_path):\n",
    "#         continue\n",
    "\n",
    "#     # Create output class folder if it doesn't exist\n",
    "#     os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "#     # Iterate through images in the sub-folder\n",
    "#     for filename in tqdm(os.listdir(class_path)):\n",
    "#         input_image_path = os.path.join(class_path, filename)\n",
    "#         output_image_path = os.path.join(output_class_path, filename.split('.')[0] + '.png')\n",
    "\n",
    "#         # Process and save the image\n",
    "#         process_image(input_image_path, output_image_path)\n",
    "#         tqdm.write(f\"Processed: {input_image_path}\")\n",
    "\n",
    "# print(\"All images processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splice_manipulation(img, augumentation_list):\n",
    "    # gt_mask = np.zeros_like(img[:,:,0]) #ground_truth_mask\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    size_patch_pcent = 0.3\n",
    "    \n",
    "    r1,c1 = random.randint(0,int(np.floor((1-size_patch_pcent)*h))), random.randint(0,int(np.floor((1-size_patch_pcent)*w)))\n",
    "    r2,c2 = random.randint(r1+int(np.floor(size_patch_pcent*h)),h), random.randint(c1+int(np.floor(size_patch_pcent*w)),w)\n",
    "    \n",
    "    patch = img[r1:r2,c1:c2,:]\n",
    "    # gt_mask[r1:r2,c1:c2,:] = 1\n",
    "    \n",
    "    augmentation = random.choice(augumentation_list)\n",
    "    if augmentation == 'H-Flip':\n",
    "        patch = np.fliplr(patch)\n",
    "    elif augmentation == 'V-Flip':\n",
    "        patch = np.flipud(patch)\n",
    "    elif augmentation == '90':\n",
    "        patch = np.rot90(patch, 1)\n",
    "    elif augmentation == '180':\n",
    "        patch = np.rot90(patch, 2)\n",
    "    elif augmentation == '270':\n",
    "        patch = np.rot90(patch, 3)\n",
    "    elif augmentation == 'Shear':\n",
    "        shear_factor = random.uniform(-0.2, 0.2)\n",
    "        shear_matrix = np.array([[1, shear_factor, 0], [0, 1, 0]])\n",
    "        patch = cv2.warpAffine(patch, shear_matrix, (patch.shape[1], patch.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "        \n",
    "    ph, pw, _ = patch.shape\n",
    "    \n",
    "    start_r, start_c = random.randint(0, h-ph), random.randint(0, w-pw)\n",
    "    img_spliced = np.copy(img)\n",
    "    img_spliced[start_r:start_r+ph, start_c:start_c+pw, :] = patch\n",
    "    # gt_mask[start_r:start_r+ph, start_c:start_c+pw] = 1\n",
    "    \n",
    "    return img_spliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class_name in os.listdir(root_folder):\n",
    "#     class_path = os.path.join(root_folder, class_name)\n",
    "    \n",
    "#     if not os.path.isdir(class_path):\n",
    "#         continue\n",
    "    \n",
    "#     augmented_images_dir = os.path.join(class_path, \"augmented_images\")\n",
    "#     os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "    \n",
    "#     image_files = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "#     num_images = len(image_files)\n",
    "    \n",
    "#     for image_file in tqdm(image_files, desc=f\"Processing images in {class_name}\"):\n",
    "#         img = cv2.imread(image_file)\n",
    "#         if img is None:\n",
    "#             print(f\"Error: Unable to load image {image_file}\")\n",
    "#             continue\n",
    "#         num_augmentations = random.randint(1, 6)\n",
    "        \n",
    "#         for _ in range(num_augmentations):\n",
    "#             augmentation_list = ['H-Flip', 'V-Flip', '90', '180', '270', 'Shear']\n",
    "#             img_spliced = create_splice_manipulation(img, augmentation_list)\n",
    "#             augmented_image_filename = f\"spliced_augmented_{os.path.basename(image_file).split('.')[0]}_{_}.jpg\"\n",
    "#             cv2.imwrite(os.path.join(augmented_images_dir, augmented_image_filename), img_spliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an iterable DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"DatasetLoad/class_dirs_final\"\n",
    "# class_dirs = [os.path.join(root_folder, d) for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
    "\n",
    "workers = 2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "beta1 = 0.5\n",
    "\n",
    "ENCODER = 'densenet201'\n",
    "ENCODER_WT = 'imagenet'\n",
    "CLASSES = [\"Blot\", \"FACS\", \"Macroscopy\", \"Microscopy\", \"None\"]\n",
    "AUXPARAMS = dict(pooling='max',dropout=0.5,activation='softmax',classes=CLASSES)\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WT)\n",
    "# nGPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSet(Dataset):\n",
    "    def __init__(self, root_path, num_samples_per_class = 7996, transform=None):\n",
    "        super().__init__()\n",
    "        self.root_path = root_path\n",
    "        self.transform = transform\n",
    "        self.classes = self.classes = sorted([d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.images = self._load_images()\n",
    "        self._print_class_distribution()\n",
    "        # print(self.class_to_idx)\n",
    "        \n",
    "        \n",
    "    def _load_images(self):\n",
    "        images = []\n",
    "        for cls_idx, cls_name in enumerate(self.classes):\n",
    "            cls_dir = os.path.join(self.root_path, cls_name)\n",
    "            img_list = [f for f in os.listdir(cls_dir) if not f.startswith('.') and os.path.isfile(os.path.join(cls_dir, f))]\n",
    "            # img_list = [f for f in os.listdir(cls_dir) if f.endswith('.png') and f.startswith('.') and os.path.isfile(os.path.join(cls_dir, f))]\n",
    "            random.shuffle(img_list)\n",
    "            img_list = img_list[:self.num_samples_per_class]\n",
    "            for img_name in img_list:\n",
    "                img_path = os.path.join(cls_dir, img_name)\n",
    "                images.append((img_path, cls_idx))\n",
    "                # print(cls_idx)\n",
    "        return images\n",
    "    \n",
    "    def _print_class_distribution(self):\n",
    "        print(\"Class distribution:\")\n",
    "        temp = []\n",
    "        for cls_name in self.classes:\n",
    "            count = sum(1 for _, label in self.images if self.classes[label] == cls_name)\n",
    "            print(f\"{cls_name}: {count} images\")\n",
    "            temp.append(count)\n",
    "        self.num_samples_per_class = min(temp)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Blot: 7996 images\n",
      "FACS: 7996 images\n",
      "Macroscopy: 7996 images\n",
      "Microscopy: 7996 images\n",
      "negetive: 7989 images\n",
      "39973\n",
      "train: 29979, val: 3997, test: 5997\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    # preprocessing_fn\n",
    "])\n",
    "dataset = ImageSet(root_path=root_folder, transform=transform)\n",
    "lenDataset = dataset.__len__()\n",
    "print(lenDataset)\n",
    "\n",
    "trainSiz = int(0.75 * len(dataset))\n",
    "valSiz = int(0.10 * len(dataset))\n",
    "testSiz = len(dataset) - trainSiz - valSiz\n",
    "\n",
    "trainSet, valSet, testSet = random_split(dataset, [trainSiz, valSiz, testSiz])\n",
    "print(f\"train: {trainSet.__len__()}, val: {valSet.__len__()}, test: {testSet.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(dataset=trainSet,batch_size=batch_size,shuffle=True, num_workers=12)\n",
    "\n",
    "val_dataloader=DataLoader(dataset=valSet,batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UDenseNet():\n",
    "#     def __init__(self, encoderName = 'densenet201', encoder_weights = 'imagenet', in_channels = 3, classes = 5):    \n",
    "#         self.encoderName = encoderName\n",
    "#         self.encoderWeights = encoder_weights\n",
    "#         self.inCh = 3\n",
    "#         self.classess = classes\n",
    "#         self.auxParams = dict(pooling='max',dropout=0.5,activation='softmax',classes=classes)\n",
    "                \n",
    "#     def get_Unet(self): \n",
    "        \n",
    "#         model = smp.Unet(\n",
    "#             encoder_name=self.encoderName,\n",
    "#             encoder_weights=self.encoderWeights,\n",
    "#             decoder_use_batchnorm= True,\n",
    "#             in_channels= self.inCh,\n",
    "#             classes=self.classess,\n",
    "#             aux_params=self.auxParams)\n",
    "        \n",
    "#         # class CustomHead(nn.Module):\n",
    "#         #     def __init__(self, base_model, classes):\n",
    "#         #         super(CustomHead, self).__init__()\n",
    "#         #         self.baseModel = base_model\n",
    "                \n",
    "#         #         self.Flatten = nn.Flatten()\n",
    "#         #         self.relu = nn.ReLU()\n",
    "                \n",
    "#         #         # self.fc1_in_features = self._get_fc1_in_features()\n",
    "#         #         # print(self.fc1_in_features)\n",
    "#         #         self.fc1 = nn.Linear(in_features=327680, out_features=384)\n",
    "#         #         self.bn1 = nn.BatchNorm1d(num_features=384)\n",
    "                \n",
    "#         #         self.dropout = nn.Dropout(0.5)\n",
    "                \n",
    "#         #         self.out = nn.Linear(384, classes)\n",
    "                \n",
    "#         #     # def _get_fc1_in_features(self):\n",
    "#         #     #     # Forward pass a dummy tensor to get the output size\n",
    "#         #     #     dummy_input = torch.randn(1, 3, 256, 256)\n",
    "#         #     #     with torch.no_grad():\n",
    "#         #     #         x = self.baseModel.encoder(dummy_input)\n",
    "                \n",
    "#         #     #     # If the encoder returns a list of tensors, concatenate them along spatial dimensions\n",
    "#         #     #     return x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "            \n",
    "#         #     def forward(self, x):\n",
    "#         #         x = self.baseModel(x)\n",
    "#         #         x = self.Flatten(x)\n",
    "#         #         # print(x.shape)\n",
    "#         #         # x = x.view(x.size(0), -1)\n",
    "#         #         x = self.fc1(x)\n",
    "#         #         x = self.bn1(x)\n",
    "#         #         x = self.relu(x)\n",
    "#         #         x = self.dropout(x)\n",
    "#         #         x = self.out(x)\n",
    "#         #         return F.softmax(x, dim=1)\n",
    "            \n",
    "#         # model = CustomHead(base_model, self.classess)    \n",
    "        \n",
    "#         return model\n",
    "\n",
    "\n",
    "\n",
    "class DenseUNet(nn.Module):\n",
    "    def __init__(self, encoder_name, encoder_weights, classes):\n",
    "        super(DenseUNet, self).__init__()\n",
    "        self.Unet = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=3,\n",
    "            classes=len(classes)\n",
    "        )\n",
    "        # self.Unet.segmentation_head = None\n",
    "        self.Unet.classification_head = nn.Sequential(\n",
    "            nn.Conv2d(1920, 1280, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.classifier = nn.Linear(1280,len(classes))\n",
    "        # Random wt for classifers as pretrained uses pretrained wts.\n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, features = self.Unet(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        x = self.classifier(features)\n",
    "        return F.softmax(x, dim=1)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseUNet(\n",
      "  (Unet): Unet(\n",
      "    (encoder): DenseNetEncoder(\n",
      "      (features): Sequential(\n",
      "        (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu0): ReLU(inplace=True)\n",
      "        (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (denseblock1): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (transition1): _Transition(\n",
      "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (denseblock2): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer7): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer8): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer9): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer10): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer11): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer12): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (transition2): _Transition(\n",
      "          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (denseblock3): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer7): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer8): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer9): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer10): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer11): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer12): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer13): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer14): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer15): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer16): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer17): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer18): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer19): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer20): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer21): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer22): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer23): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer24): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer25): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer26): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer27): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer28): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer29): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer30): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer31): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer32): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer33): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer34): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer35): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer36): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer37): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer38): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer39): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer40): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer41): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer42): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer43): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer44): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer45): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer46): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer47): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer48): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (transition3): _Transition(\n",
      "          (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (denseblock4): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer7): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer8): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer9): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer10): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer11): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer12): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer13): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer14): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer15): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer16): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer17): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer18): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer19): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer20): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer21): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer22): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer23): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer24): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer25): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer26): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer27): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer28): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer29): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer30): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer31): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer32): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (decoder): UnetDecoder(\n",
      "      (center): Identity()\n",
      "      (blocks): ModuleList(\n",
      "        (0): DecoderBlock(\n",
      "          (conv1): Conv2dReLU(\n",
      "            (0): Conv2d(3712, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention1): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "          (conv2): Conv2dReLU(\n",
      "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention2): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): DecoderBlock(\n",
      "          (conv1): Conv2dReLU(\n",
      "            (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention1): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "          (conv2): Conv2dReLU(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention2): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "        )\n",
      "        (2): DecoderBlock(\n",
      "          (conv1): Conv2dReLU(\n",
      "            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention1): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "          (conv2): Conv2dReLU(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention2): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "        )\n",
      "        (3): DecoderBlock(\n",
      "          (conv1): Conv2dReLU(\n",
      "            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention1): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "          (conv2): Conv2dReLU(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention2): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "        )\n",
      "        (4): DecoderBlock(\n",
      "          (conv1): Conv2dReLU(\n",
      "            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention1): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "          (conv2): Conv2dReLU(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (attention2): Attention(\n",
      "            (attention): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (segmentation_head): SegmentationHead(\n",
      "      (0): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): Identity()\n",
      "      (2): Activation(\n",
      "        (activation): Identity()\n",
      "      )\n",
      "    )\n",
      "    (classification_head): Sequential(\n",
      "      (0): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): AdaptiveAvgPool2d(output_size=1)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=1280, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DenseUNet(ENCODER, ENCODER_WT, CLASSES).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, batch_size, device):\n",
    "    model.train()\n",
    "    track_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(imgs)\n",
    "\n",
    "        loss = loss_fn(pred, labels)\n",
    "        track_loss += loss.item()\n",
    "        correct_predictions += torch.sum(torch.argmax(pred, dim=1) == labels).item()\n",
    "\n",
    "        running_loss = round(track_loss / (i + 1), 2)\n",
    "        running_acc = round((correct_predictions / ((i + 1) * batch_size)) * 100, 2)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Batch:\", i + 1, \"/\", len(dataloader), \"Running Loss:\", running_loss, \"Running Accuracy:\", running_acc)\n",
    "\n",
    "    epoch_loss = running_loss\n",
    "    epoch_acc = running_acc\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_one_epoch(dataloader, model, loss_fn, batch_size, device):\n",
    "    model.eval()\n",
    "    track_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            loss = loss_fn(pred, labels)\n",
    "            track_loss += loss.item()\n",
    "            correct_predictions += torch.sum(torch.argmax(pred, dim=1) == labels).item()\n",
    "\n",
    "            running_loss = round(track_loss / (i + 1), 2)\n",
    "            running_acc = round((correct_predictions / ((i + 1) * batch_size)) * 100, 2)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(\"Validation Batch:\", i + 1, \"/\", len(dataloader), \"Running Loss:\", running_loss, \"Running Accuracy:\", running_acc)\n",
    "\n",
    "        epoch_loss = running_loss\n",
    "        epoch_acc = running_acc\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "EPOCHS: 0\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.61 Running Accuracy: 25.0\n",
      "Batch: 101 / 1874 Running Loss: 1.44 Running Accuracy: 46.53\n",
      "Batch: 201 / 1874 Running Loss: 1.44 Running Accuracy: 46.33\n",
      "Batch: 301 / 1874 Running Loss: 1.45 Running Accuracy: 45.14\n",
      "Batch: 401 / 1874 Running Loss: 1.47 Running Accuracy: 42.92\n",
      "Batch: 501 / 1874 Running Loss: 1.5 Running Accuracy: 40.12\n",
      "Batch: 601 / 1874 Running Loss: 1.52 Running Accuracy: 38.71\n",
      "Batch: 701 / 1874 Running Loss: 1.52 Running Accuracy: 38.05\n",
      "Batch: 801 / 1874 Running Loss: 1.53 Running Accuracy: 37.62\n",
      "Batch: 901 / 1874 Running Loss: 1.53 Running Accuracy: 37.31\n",
      "Batch: 1001 / 1874 Running Loss: 1.53 Running Accuracy: 37.04\n",
      "Batch: 1101 / 1874 Running Loss: 1.53 Running Accuracy: 37.0\n",
      "Batch: 1201 / 1874 Running Loss: 1.52 Running Accuracy: 38.23\n",
      "Batch: 1301 / 1874 Running Loss: 1.51 Running Accuracy: 39.36\n",
      "Batch: 1401 / 1874 Running Loss: 1.5 Running Accuracy: 40.53\n",
      "Batch: 1501 / 1874 Running Loss: 1.5 Running Accuracy: 40.75\n",
      "Batch: 1601 / 1874 Running Loss: 1.49 Running Accuracy: 41.31\n",
      "Batch: 1701 / 1874 Running Loss: 1.49 Running Accuracy: 41.63\n",
      "Batch: 1801 / 1874 Running Loss: 1.48 Running Accuracy: 42.1\n",
      "Validation Batch: 1 / 250 Running Loss: 1.47 Running Accuracy: 43.75\n",
      "Validation Batch: 101 / 250 Running Loss: 1.38 Running Accuracy: 52.72\n",
      "Validation Batch: 201 / 250 Running Loss: 1.38 Running Accuracy: 51.96\n",
      "Epoch 1/20 - Training Loss: 1.48, Training Accuracy: 42.46% - Validation Loss: 1.38, Validation Accuracy: 52.23%\n",
      "------------------------------------------------\n",
      "EPOCHS: 1\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.65 Running Accuracy: 25.0\n",
      "Batch: 101 / 1874 Running Loss: 1.38 Running Accuracy: 52.6\n",
      "Batch: 201 / 1874 Running Loss: 1.39 Running Accuracy: 51.8\n",
      "Batch: 301 / 1874 Running Loss: 1.4 Running Accuracy: 49.85\n",
      "Batch: 401 / 1874 Running Loss: 1.4 Running Accuracy: 50.76\n",
      "Batch: 501 / 1874 Running Loss: 1.39 Running Accuracy: 51.58\n",
      "Batch: 601 / 1874 Running Loss: 1.38 Running Accuracy: 52.14\n",
      "Batch: 701 / 1874 Running Loss: 1.39 Running Accuracy: 51.57\n",
      "Batch: 801 / 1874 Running Loss: 1.39 Running Accuracy: 51.39\n",
      "Batch: 901 / 1874 Running Loss: 1.39 Running Accuracy: 51.36\n",
      "Batch: 1001 / 1874 Running Loss: 1.39 Running Accuracy: 51.07\n",
      "Batch: 1101 / 1874 Running Loss: 1.39 Running Accuracy: 51.38\n",
      "Batch: 1201 / 1874 Running Loss: 1.39 Running Accuracy: 51.38\n",
      "Batch: 1301 / 1874 Running Loss: 1.39 Running Accuracy: 51.19\n",
      "Batch: 1401 / 1874 Running Loss: 1.39 Running Accuracy: 51.11\n",
      "Batch: 1501 / 1874 Running Loss: 1.39 Running Accuracy: 51.17\n",
      "Batch: 1601 / 1874 Running Loss: 1.39 Running Accuracy: 50.94\n",
      "Batch: 1701 / 1874 Running Loss: 1.4 Running Accuracy: 50.5\n",
      "Batch: 1801 / 1874 Running Loss: 1.4 Running Accuracy: 50.42\n",
      "Validation Batch: 1 / 250 Running Loss: 1.29 Running Accuracy: 62.5\n",
      "Validation Batch: 101 / 250 Running Loss: 1.35 Running Accuracy: 55.01\n",
      "Validation Batch: 201 / 250 Running Loss: 1.37 Running Accuracy: 53.86\n",
      "Epoch 2/20 - Training Loss: 1.4, Training Accuracy: 50.31% - Validation Loss: 1.37, Validation Accuracy: 53.6%\n",
      "------------------------------------------------\n",
      "EPOCHS: 2\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.4 Running Accuracy: 50.0\n",
      "Batch: 101 / 1874 Running Loss: 1.39 Running Accuracy: 51.55\n",
      "Batch: 201 / 1874 Running Loss: 1.4 Running Accuracy: 50.72\n",
      "Batch: 301 / 1874 Running Loss: 1.39 Running Accuracy: 51.0\n",
      "Batch: 401 / 1874 Running Loss: 1.39 Running Accuracy: 51.11\n",
      "Batch: 501 / 1874 Running Loss: 1.38 Running Accuracy: 51.97\n",
      "Batch: 601 / 1874 Running Loss: 1.37 Running Accuracy: 53.41\n",
      "Batch: 701 / 1874 Running Loss: 1.36 Running Accuracy: 54.26\n",
      "Batch: 801 / 1874 Running Loss: 1.36 Running Accuracy: 54.71\n",
      "Batch: 901 / 1874 Running Loss: 1.36 Running Accuracy: 54.01\n",
      "Batch: 1001 / 1874 Running Loss: 1.37 Running Accuracy: 53.65\n",
      "Batch: 1101 / 1874 Running Loss: 1.37 Running Accuracy: 53.02\n",
      "Batch: 1201 / 1874 Running Loss: 1.37 Running Accuracy: 53.21\n",
      "Batch: 1301 / 1874 Running Loss: 1.37 Running Accuracy: 53.36\n",
      "Batch: 1401 / 1874 Running Loss: 1.37 Running Accuracy: 53.01\n",
      "Batch: 1501 / 1874 Running Loss: 1.37 Running Accuracy: 53.61\n",
      "Batch: 1601 / 1874 Running Loss: 1.36 Running Accuracy: 54.15\n",
      "Batch: 1701 / 1874 Running Loss: 1.36 Running Accuracy: 54.43\n",
      "Batch: 1801 / 1874 Running Loss: 1.36 Running Accuracy: 54.67\n",
      "Validation Batch: 1 / 250 Running Loss: 1.28 Running Accuracy: 62.5\n",
      "Validation Batch: 101 / 250 Running Loss: 1.28 Running Accuracy: 62.44\n",
      "Validation Batch: 201 / 250 Running Loss: 1.29 Running Accuracy: 61.57\n",
      "Epoch 3/20 - Training Loss: 1.35, Training Accuracy: 54.89% - Validation Loss: 1.29, Validation Accuracy: 61.15%\n",
      "------------------------------------------------\n",
      "EPOCHS: 3\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.22 Running Accuracy: 68.75\n",
      "Batch: 101 / 1874 Running Loss: 1.32 Running Accuracy: 58.35\n",
      "Batch: 201 / 1874 Running Loss: 1.31 Running Accuracy: 59.36\n",
      "Batch: 301 / 1874 Running Loss: 1.32 Running Accuracy: 58.58\n",
      "Batch: 401 / 1874 Running Loss: 1.31 Running Accuracy: 59.01\n",
      "Batch: 501 / 1874 Running Loss: 1.3 Running Accuracy: 59.93\n",
      "Batch: 601 / 1874 Running Loss: 1.29 Running Accuracy: 60.98\n",
      "Batch: 701 / 1874 Running Loss: 1.28 Running Accuracy: 62.05\n",
      "Batch: 801 / 1874 Running Loss: 1.28 Running Accuracy: 62.85\n",
      "Batch: 901 / 1874 Running Loss: 1.27 Running Accuracy: 63.09\n",
      "Batch: 1001 / 1874 Running Loss: 1.27 Running Accuracy: 63.26\n",
      "Batch: 1101 / 1874 Running Loss: 1.27 Running Accuracy: 63.79\n",
      "Batch: 1201 / 1874 Running Loss: 1.26 Running Accuracy: 64.2\n",
      "Batch: 1301 / 1874 Running Loss: 1.26 Running Accuracy: 64.74\n",
      "Batch: 1401 / 1874 Running Loss: 1.25 Running Accuracy: 65.1\n",
      "Batch: 1501 / 1874 Running Loss: 1.25 Running Accuracy: 65.36\n",
      "Batch: 1601 / 1874 Running Loss: 1.26 Running Accuracy: 64.89\n",
      "Batch: 1701 / 1874 Running Loss: 1.25 Running Accuracy: 65.09\n",
      "Batch: 1801 / 1874 Running Loss: 1.25 Running Accuracy: 65.21\n",
      "Validation Batch: 1 / 250 Running Loss: 1.09 Running Accuracy: 81.25\n",
      "Validation Batch: 101 / 250 Running Loss: 1.15 Running Accuracy: 75.74\n",
      "Validation Batch: 201 / 250 Running Loss: 1.15 Running Accuracy: 75.22\n",
      "Epoch 4/20 - Training Loss: 1.25, Training Accuracy: 65.42% - Validation Loss: 1.16, Validation Accuracy: 74.42%\n",
      "------------------------------------------------\n",
      "EPOCHS: 4\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.03 Running Accuracy: 87.5\n",
      "Batch: 101 / 1874 Running Loss: 1.18 Running Accuracy: 72.03\n",
      "Batch: 201 / 1874 Running Loss: 1.18 Running Accuracy: 71.95\n",
      "Batch: 301 / 1874 Running Loss: 1.17 Running Accuracy: 72.94\n",
      "Batch: 401 / 1874 Running Loss: 1.18 Running Accuracy: 72.58\n",
      "Batch: 501 / 1874 Running Loss: 1.18 Running Accuracy: 72.43\n",
      "Batch: 601 / 1874 Running Loss: 1.19 Running Accuracy: 71.83\n",
      "Batch: 701 / 1874 Running Loss: 1.18 Running Accuracy: 72.33\n",
      "Batch: 801 / 1874 Running Loss: 1.18 Running Accuracy: 72.5\n",
      "Batch: 901 / 1874 Running Loss: 1.18 Running Accuracy: 72.7\n",
      "Batch: 1001 / 1874 Running Loss: 1.18 Running Accuracy: 72.73\n",
      "Batch: 1101 / 1874 Running Loss: 1.18 Running Accuracy: 72.83\n",
      "Batch: 1201 / 1874 Running Loss: 1.18 Running Accuracy: 72.75\n",
      "Batch: 1301 / 1874 Running Loss: 1.18 Running Accuracy: 72.9\n",
      "Batch: 1401 / 1874 Running Loss: 1.17 Running Accuracy: 72.95\n",
      "Batch: 1501 / 1874 Running Loss: 1.17 Running Accuracy: 73.03\n",
      "Batch: 1601 / 1874 Running Loss: 1.17 Running Accuracy: 73.25\n",
      "Batch: 1701 / 1874 Running Loss: 1.17 Running Accuracy: 73.15\n",
      "Batch: 1801 / 1874 Running Loss: 1.17 Running Accuracy: 73.05\n",
      "Validation Batch: 1 / 250 Running Loss: 1.09 Running Accuracy: 81.25\n",
      "Validation Batch: 101 / 250 Running Loss: 1.08 Running Accuracy: 81.93\n",
      "Validation Batch: 201 / 250 Running Loss: 1.09 Running Accuracy: 81.65\n",
      "Epoch 5/20 - Training Loss: 1.17, Training Accuracy: 73.2% - Validation Loss: 1.09, Validation Accuracy: 81.15%\n",
      "------------------------------------------------\n",
      "EPOCHS: 5\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.09 Running Accuracy: 81.25\n",
      "Batch: 101 / 1874 Running Loss: 1.15 Running Accuracy: 75.19\n",
      "Batch: 201 / 1874 Running Loss: 1.14 Running Accuracy: 76.18\n",
      "Batch: 301 / 1874 Running Loss: 1.14 Running Accuracy: 76.29\n",
      "Batch: 401 / 1874 Running Loss: 1.17 Running Accuracy: 73.36\n",
      "Batch: 501 / 1874 Running Loss: 1.23 Running Accuracy: 67.03\n",
      "Batch: 601 / 1874 Running Loss: 1.27 Running Accuracy: 63.6\n",
      "Batch: 701 / 1874 Running Loss: 1.27 Running Accuracy: 63.69\n",
      "Batch: 801 / 1874 Running Loss: 1.26 Running Accuracy: 64.86\n",
      "Batch: 901 / 1874 Running Loss: 1.24 Running Accuracy: 66.05\n",
      "Batch: 1001 / 1874 Running Loss: 1.24 Running Accuracy: 66.5\n",
      "Batch: 1101 / 1874 Running Loss: 1.24 Running Accuracy: 66.87\n",
      "Batch: 1201 / 1874 Running Loss: 1.23 Running Accuracy: 67.27\n",
      "Batch: 1301 / 1874 Running Loss: 1.23 Running Accuracy: 67.66\n",
      "Batch: 1401 / 1874 Running Loss: 1.22 Running Accuracy: 68.21\n",
      "Batch: 1501 / 1874 Running Loss: 1.22 Running Accuracy: 68.36\n",
      "Batch: 1601 / 1874 Running Loss: 1.22 Running Accuracy: 68.84\n",
      "Batch: 1701 / 1874 Running Loss: 1.21 Running Accuracy: 69.19\n",
      "Batch: 1801 / 1874 Running Loss: 1.21 Running Accuracy: 69.35\n",
      "Validation Batch: 1 / 250 Running Loss: 1.09 Running Accuracy: 81.25\n",
      "Validation Batch: 101 / 250 Running Loss: 1.21 Running Accuracy: 69.37\n",
      "Validation Batch: 201 / 250 Running Loss: 1.22 Running Accuracy: 68.84\n",
      "Epoch 6/20 - Training Loss: 1.21, Training Accuracy: 69.05% - Validation Loss: 1.22, Validation Accuracy: 68.65%\n",
      "Warning: Potential overfitting!\n",
      "------------------------------------------------\n",
      "EPOCHS: 6\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.28 Running Accuracy: 62.5\n",
      "Batch: 101 / 1874 Running Loss: 1.2 Running Accuracy: 70.73\n",
      "Batch: 201 / 1874 Running Loss: 1.18 Running Accuracy: 72.39\n",
      "Batch: 301 / 1874 Running Loss: 1.18 Running Accuracy: 72.34\n",
      "Batch: 401 / 1874 Running Loss: 1.18 Running Accuracy: 72.69\n",
      "Batch: 501 / 1874 Running Loss: 1.17 Running Accuracy: 73.03\n",
      "Batch: 601 / 1874 Running Loss: 1.17 Running Accuracy: 73.34\n",
      "Batch: 701 / 1874 Running Loss: 1.17 Running Accuracy: 73.52\n",
      "Batch: 801 / 1874 Running Loss: 1.17 Running Accuracy: 73.81\n",
      "Batch: 901 / 1874 Running Loss: 1.17 Running Accuracy: 73.35\n",
      "Batch: 1001 / 1874 Running Loss: 1.18 Running Accuracy: 72.33\n",
      "Batch: 1101 / 1874 Running Loss: 1.18 Running Accuracy: 72.68\n",
      "Batch: 1201 / 1874 Running Loss: 1.18 Running Accuracy: 72.88\n",
      "Batch: 1301 / 1874 Running Loss: 1.17 Running Accuracy: 73.16\n",
      "Batch: 1401 / 1874 Running Loss: 1.17 Running Accuracy: 73.6\n",
      "Batch: 1501 / 1874 Running Loss: 1.17 Running Accuracy: 73.8\n",
      "Batch: 1601 / 1874 Running Loss: 1.16 Running Accuracy: 74.11\n",
      "Batch: 1701 / 1874 Running Loss: 1.16 Running Accuracy: 74.47\n",
      "Batch: 1801 / 1874 Running Loss: 1.16 Running Accuracy: 74.81\n",
      "Validation Batch: 1 / 250 Running Loss: 1.09 Running Accuracy: 81.25\n",
      "Validation Batch: 101 / 250 Running Loss: 1.07 Running Accuracy: 83.91\n",
      "Validation Batch: 201 / 250 Running Loss: 1.07 Running Accuracy: 83.36\n",
      "Epoch 7/20 - Training Loss: 1.16, Training Accuracy: 74.93% - Validation Loss: 1.07, Validation Accuracy: 83.12%\n",
      "------------------------------------------------\n",
      "EPOCHS: 7\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 0.97 Running Accuracy: 93.75\n",
      "Batch: 101 / 1874 Running Loss: 1.12 Running Accuracy: 78.71\n",
      "Batch: 201 / 1874 Running Loss: 1.11 Running Accuracy: 79.35\n",
      "Batch: 301 / 1874 Running Loss: 1.12 Running Accuracy: 78.78\n",
      "Batch: 401 / 1874 Running Loss: 1.11 Running Accuracy: 79.36\n",
      "Batch: 501 / 1874 Running Loss: 1.11 Running Accuracy: 79.54\n",
      "Batch: 601 / 1874 Running Loss: 1.11 Running Accuracy: 79.53\n",
      "Batch: 701 / 1874 Running Loss: 1.11 Running Accuracy: 79.41\n",
      "Batch: 801 / 1874 Running Loss: 1.11 Running Accuracy: 79.21\n",
      "Batch: 901 / 1874 Running Loss: 1.11 Running Accuracy: 79.15\n",
      "Batch: 1001 / 1874 Running Loss: 1.11 Running Accuracy: 79.03\n",
      "Batch: 1101 / 1874 Running Loss: 1.12 Running Accuracy: 78.76\n",
      "Batch: 1201 / 1874 Running Loss: 1.12 Running Accuracy: 78.82\n",
      "Batch: 1301 / 1874 Running Loss: 1.12 Running Accuracy: 78.72\n",
      "Batch: 1401 / 1874 Running Loss: 1.12 Running Accuracy: 78.93\n",
      "Batch: 1501 / 1874 Running Loss: 1.11 Running Accuracy: 79.06\n",
      "Batch: 1601 / 1874 Running Loss: 1.12 Running Accuracy: 78.81\n",
      "Batch: 1701 / 1874 Running Loss: 1.12 Running Accuracy: 78.74\n",
      "Batch: 1801 / 1874 Running Loss: 1.12 Running Accuracy: 78.57\n",
      "Validation Batch: 1 / 250 Running Loss: 1.15 Running Accuracy: 75.0\n",
      "Validation Batch: 101 / 250 Running Loss: 1.15 Running Accuracy: 75.25\n",
      "Validation Batch: 201 / 250 Running Loss: 1.16 Running Accuracy: 74.53\n",
      "Epoch 8/20 - Training Loss: 1.12, Training Accuracy: 78.45% - Validation Loss: 1.17, Validation Accuracy: 73.6%\n",
      "Warning: Potential overfitting!\n",
      "------------------------------------------------\n",
      "EPOCHS: 8\n",
      "------------------------------------------------\n",
      "Batch: 1 / 1874 Running Loss: 1.28 Running Accuracy: 62.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate_one_epoch(val_dataloader, model, loss_fn, batch_size, device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% - Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(dataloader, model, loss_fn, optimizer, batch_size, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, labels)\n\u001b[1;32m     13\u001b[0m track_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 84\u001b[0m, in \u001b[0;36mDenseUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 84\u001b[0m     _, features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     86\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(features)\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/segmentation_models_pytorch/base/model.py:29\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m---> 29\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m     32\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/densenet.py:79\u001b[0m, in \u001b[0;36mDenseNetEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m     81\u001b[0m         x, skip \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torchvision/models/densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torchvision/models/densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcated_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"EPOCHS: {epoch}\")\n",
    "    print(\"------------------------------------------------\")\n",
    "    train_loss, train_acc = train_one_epoch(train_dataloader, model, loss_fn, optimizer, batch_size, device)\n",
    "\n",
    "    val_loss, val_acc = validate_one_epoch(val_dataloader, model, loss_fn, batch_size, device)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS} - Training Loss: {train_loss}, Training Accuracy: {train_acc}% - Validation Loss: {val_loss}, Validation Accuracy: {val_acc}%\")\n",
    "    if val_loss > train_loss:\n",
    "        print(\"Warning: Potential overfitting!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader=DataLoader(dataset=testSet,batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Batch: 1 / 375 Running Loss: 1.09 Running Accuracy: 81.25\n",
      "Validation Batch: 101 / 375 Running Loss: 1.08 Running Accuracy: 82.61\n",
      "Validation Batch: 201 / 375 Running Loss: 1.08 Running Accuracy: 82.37\n",
      "Validation Batch: 301 / 375 Running Loss: 1.07 Running Accuracy: 83.2\n"
     ]
    }
   ],
   "source": [
    "tesr_loss, test_acc = validate_one_epoch(test_dataloader, model, loss_fn, batch_size, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
